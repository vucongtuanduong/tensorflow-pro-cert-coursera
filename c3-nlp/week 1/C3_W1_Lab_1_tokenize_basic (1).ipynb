{"cells":[{"cell_type":"markdown","metadata":{"cell_id":"a8528ca046184a81becb9a32d267e16e","deepnote_cell_type":"markdown"},"source":"<a href=\"https://colab.research.google.com/github/https-deeplearning-ai/tensorflow-1-public/blob/master/C3/W1/ungraded_labs/C3_W1_Lab_1_tokenize_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>","block_group":"82805ee2ddee4c2380136f0563002ae6"},{"cell_type":"markdown","metadata":{"id":"rL-LzAqpoGLC","cell_id":"61bb21727e22403cab7ca86607f1e00e","deepnote_cell_type":"markdown"},"source":"# Ungraded Lab: Tokenizer Basics\n\nIn most NLP tasks, the initial step in preparing your data is to extract a vocabulary of words from your *corpus* (i.e. input texts). You will need to define how to represent the texts into numerical representations which can be used to train a neural network. These representations are called *tokens* and Tensorflow and Keras makes it easy to generate these using its APIs. You will see how to do that in the next cells.","block_group":"3215ccce722646a68870a137c471f4c0"},{"cell_type":"markdown","metadata":{"id":"-nt3uR9TPrUt","cell_id":"18507a0baff646a691c6e92681fcdee4","deepnote_cell_type":"markdown"},"source":"## Generating the vocabulary\n\nIn this notebook, you will look first at how you can provide a look up dictionary for each word. The code below takes a list of sentences, then takes each word in those sentences and assigns it to an integer. This is done using the [fit_on_texts()](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#fit_on_texts) method and you can get the result by looking at the `word_index` property. More frequent words have a lower index.","block_group":"53121dc027c849b0b522455826038b83"},{"cell_type":"code","metadata":{"id":"zaCMcjMQifQc","source_hash":"6360a49","execution_start":1695547038100,"execution_millis":3077,"deepnote_to_be_reexecuted":false,"cell_id":"d3e114f6963c4cbe8c724a34bbd73017","deepnote_cell_type":"code"},"source":"from tensorflow.keras.preprocessing.text import Tokenizer\n\n# Define input sentences\nsentences = [\n    'i love my dog',\n    'I, love my cat'\n    ]\n\n# Initialize the Tokenizer class\ntokenizer = Tokenizer(num_words = 100)\n\n# Generate indices for each word in the corpus\ntokenizer.fit_on_texts(sentences)\n\n# Get the indices and print it\nword_index = tokenizer.word_index\nprint(word_index)","block_group":"c5aa956774f5402aa3494f82f749aa8c","execution_count":1,"outputs":[{"name":"stderr","text":"2023-09-24 09:17:18.056648: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-09-24 09:17:18.222547: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-09-24 09:17:18.222589: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-09-24 09:17:18.269463: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-09-24 09:17:19.326543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-09-24 09:17:19.326624: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-09-24 09:17:19.326634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"uTPWesNaRdX2","cell_id":"2f1d6b1a0728456993cfb664ec4ff68f","deepnote_cell_type":"markdown"},"source":"The `num_words` parameter used in the initializer specifies the maximum number of words minus one (based on frequency) to keep when generating sequences. You will see this in a later exercise. For now, the important thing to note is it does not affect how the `word_index` dictionary is generated. You can try passing `1` instead of `100` as shown on the next cell and you will arrive at the same `word_index`. \n\nAlso notice that by default, all punctuation is ignored and words are converted to lower case. You can override these behaviors by modifying the `filters` and `lower` arguments of the `Tokenizer` class as described [here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer#arguments). You can try modifying these in the next cell below and compare the output to the one generated above.","block_group":"9bf2bd3f41494e9e849e3463d4aaa3e0"},{"cell_type":"code","metadata":{"id":"VX1A1pDNoVKm","source_hash":"fc08f551","execution_start":1695547040930,"execution_millis":15,"deepnote_to_be_reexecuted":false,"cell_id":"1356e82d177f4f28ac3efb7541546206","deepnote_cell_type":"code"},"source":"# Define input sentences\nsentences = [\n    'i love my dog',\n    'I, love my cat',\n    'You love my dog!'\n]\n\n# Initialize the Tokenizer class\ntokenizer = Tokenizer(num_words = 1)\n\n# Generate indices for each word in the corpus\ntokenizer.fit_on_texts(sentences)\n\n# Get the indices and print it\nword_index = tokenizer.word_index\nprint(word_index)","block_group":"44c795b9895f4b13a262aece42196e13","execution_count":2,"outputs":[{"name":"stdout","text":"{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n","output_type":"stream"}]},{"cell_type":"markdown","metadata":{"id":"c9LFfwBffDaj","cell_id":"1ad7c1a20b3643e6bbfa5ad808bdbc96","deepnote_cell_type":"markdown"},"source":"That concludes this short exercise on tokenizing input texts!","block_group":"e594eff9773240eb9e9ab79c14db9a14"},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=56659abd-468c-479e-9cc1-59c4e3afb148' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"C3_W1_Lab_1_tokenize_basic.ipynb","provenance":[{"file_id":"https://github.com/https-deeplearning-ai/tensorflow-1-public/blob/adding_C3/C3/W1/ungraded_labs/C3_W1_Lab_1_tokenize_basic.ipynb","timestamp":1642431620601}],"private_outputs":true,"collapsed_sections":[]},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","version":"3.7.4","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"7111e0d9a100436d87ce3c4cd65174c6","deepnote_execution_queue":[]}}